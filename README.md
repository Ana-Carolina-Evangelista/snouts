<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=FFD101&height=240&section=header&text=Snouts%20&fontSize=50&fontColor=fff&animation=twinkling&fontAlignY=40&desc=An%20app%20that%20identifies%20barks%20and%20meows%20using%20Machine%20Learning%20!&descAlignY=60&descSize=18">

## Sobre o Projeto
Este projeto utiliza **Machine Learning** com **CoreML** e **CreateML** para classificar sons de animais (gatos e cachorros). Ao identificar corretamente o som, o app exibe **uma imagem engraÃ§ada** do animal correspondente â€” tornando a experiÃªncia leve, divertida e didÃ¡tica.

## ğŸ¯ Objetivo

- Explorar o uso de **CreateML** para treinar um modelo de classificaÃ§Ã£o de Ã¡udio.
- Integrar o modelo ao app com **CoreML**.
- Desenvolver uma aplicaÃ§Ã£o prÃ¡tica e interativa com foco em som e imagem.

## ğŸ› ï¸ Tecnologias Utilizadas

- **CreateML** (treinamento do modelo)
- **CoreML** (integraÃ§Ã£o com app iOS)
- **Swift**
- **Xcode**
- Dataset customizado com sons de gatos e cachorros (em `.wav`)

## ğŸ” Como Funciona

1. O modelo foi treinado com exemplos de sons de gatos e cachorros.
2. No app, o microfone capta o som.
3. O som Ã© processado e classificado como "gato" ou "cachorro".
4. O app exibe uma imagem engraÃ§ada do animal correspondente. ğŸ‰

## ğŸ‘¥ Desenvolvido por

[Alana Abdias (github.com/Alana-Abdias)]
[Ana Carolina (github.com/@Ana-Carolina-Evangelista)]
[Carolina Sun (github.com/@carolssun)]
[Jonas Melo (github.com/@JonasFNMelo)]
[Pedro Henrique Moreiras (github.com/@pepeu31)]
[Rafael Neves (github.com/@OliveiraRNeves)]
