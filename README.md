<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=FFD101&height=240&section=header&text=Snouts%20&fontSize=50&fontColor=fff&animation=twinkling&fontAlignY=40&desc=An%20app%20that%20identifies%20barks%20and%20meows%20using%20Machine%20Learning%20!&descAlignY=60&descSize=18">

## Sobre o Projeto
Este projeto utiliza **Machine Learning** com **CoreML** e **CreateML** para classificar sons de animais (gatos e cachorros). Ao identificar corretamente o som, o app exibe **uma imagem engraçada** do animal correspondente — tornando a experiência leve, divertida e didática.

## 🎯 Objetivo

- Explorar o uso de **CreateML** para treinar um modelo de classificação de áudio.
- Integrar o modelo ao app com **CoreML**.
- Desenvolver uma aplicação prática e interativa com foco em som e imagem.

## 🛠️ Tecnologias Utilizadas

- **CreateML** (treinamento do modelo)
- **CoreML** (integração com app iOS)
- **Swift**
- **Xcode**
- Dataset customizado com sons de gatos e cachorros (em `.wav`)

## 🔍 Como Funciona

1. O modelo foi treinado com exemplos de sons de gatos e cachorros.
2. No app, o microfone capta o som.
3. O som é processado e classificado como "gato" ou "cachorro".
4. O app exibe uma imagem engraçada do animal correspondente. 🎉

## 👥 Desenvolvido por

[Alana Abdias (github.com/Alana-Abdias)]
[Ana Carolina (github.com/@Ana-Carolina-Evangelista)]
[Carolina Sun (github.com/@carolssun)]
[Jonas Melo (github.com/@JonasFNMelo)]
[Pedro Henrique Moreiras (github.com/@pepeu31)]
[Rafael Neves (github.com/@OliveiraRNeves)]
